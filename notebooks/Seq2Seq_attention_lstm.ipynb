{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRmTmYstdUZM",
        "outputId": "ffa87ada-beaf-42eb-8cab-ffa71e37d30f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from nltk import download\n",
        "download('stopwords')\n",
        "download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings\n",
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", -1)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN9PYaCZdKen",
        "outputId": "6b74c6f9-efb2-4c33-96d7-c11c4a45632f"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evKvuB_MdTNw"
      },
      "source": [
        "data=pd.read_csv(\"abstract_summary.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBZ92dDQdj4W"
      },
      "source": [
        "data.dropna(axis=0,inplace=True) #dropping na"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZzq8g43dmcD"
      },
      "source": [
        "all_stopwords = stopwords.words('english')\n",
        "\n",
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    text_tokens = newString.split()\n",
        "    tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "    newString = \" \".join(tokens_without_sw)\n",
        "    newString = re.sub(r\"\\s+\",\" \",newString)\n",
        "    \n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf97vnWydo1V"
      },
      "source": [
        "#call the function\n",
        "cleaned_text = [text_cleaner(t) for t in data['Text']]\n",
        "cleaned_summary = [text_cleaner(t) for t in data['Summary']]\n",
        "\n",
        "data['cleaned_text'] = cleaned_text\n",
        "data['cleaned_summary'] = cleaned_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "BeOJ3nRXd78_",
        "outputId": "d43c2076-5843-44d5-c547-f9c342376448"
      },
      "source": [
        "# distribution of sequences\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "for i in cleaned_text:\n",
        "    text_word_count.append(len(i.split()))\n",
        "for i in cleaned_summary:\n",
        "    summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text': text_word_count, 'summary': summary_word_count})\n",
        "length_df.hist(bins=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-jq8y72eSYv",
        "outputId": "0294bd5b-0809-4984-99a3-c8074df80776"
      },
      "source": [
        "count = 0\n",
        "for i in cleaned_text:\n",
        "    if(len(i.split())<=250):\n",
        "        count += 1\n",
        "print(count/len(cleaned_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9090909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6TCIOp0enar",
        "outputId": "5ea778dd-4228-4b8d-9344-01e32574f4c8"
      },
      "source": [
        "count = 0\n",
        "for i in cleaned_summary:\n",
        "    if(len(i.split())<=120):\n",
        "        count += 1\n",
        "print(count/len(cleaned_summary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8181818181818182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfkemd7Ke6ti"
      },
      "source": [
        "max_summary_len = 120\n",
        "max_text_len = 250\n",
        "\n",
        "cleaned_text = np.array(cleaned_text)\n",
        "cleaned_summary = np.array(cleaned_summary)\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    \n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "\n",
        "df=pd.DataFrame({'text':short_text, 'summary':short_summary})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RHef468y5cc"
      },
      "source": [
        "Text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbsWk--LxVSN"
      },
      "source": [
        "# define dummy data and precproces them\n",
        "docs = short_text\n",
        "\n",
        "# train fasttext from gensim api\n",
        "ft = FastText(size=10, window=2, min_count=1, seed=33)\n",
        "ft.build_vocab(docs)\n",
        "ft.train(docs, total_examples=ft.corpus_count, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmmGUCQHxQsD"
      },
      "source": [
        "# prepare text for keras neural network\n",
        "MAX_LEN = 120\n",
        "\n",
        "tokenizer = tensorflow.keras.preprocessing.text.Tokenizer(lower=True)\n",
        "tokenizer.fit_on_texts(docs)\n",
        "\n",
        "sequence_docs = tokenizer.texts_to_sequences(docs)\n",
        "sequence_docs = tensorflow.keras.preprocessing.sequence.pad_sequences(sequence_docs, maxlen=MAX_LEN)\n",
        "\n",
        "# extract fasttext learned embedding and put them in a numpy array\n",
        "embedding_matrix_ft = np.random.random((len(tokenizer.word_index) + 1, ft.vector_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3sI8wlE4GG6",
        "outputId": "b1c9b1c0-413a-48d2-d6f6-58c682bb33eb"
      },
      "source": [
        "sequence_docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   30,  396,  397],\n",
              "       [   0,    0,    0, ...,   57,  221,  212],\n",
              "       [   0,    0,    0, ...,   41,   33,  138],\n",
              "       ...,\n",
              "       [  74,    1,  191, ...,  932,  120,    1],\n",
              "       [ 367,   12,    1, ...,  186,  969,  970],\n",
              "       [ 369,  994,    8, ..., 1034, 1035, 1036]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWe20K58xxw4"
      },
      "source": [
        "pas = 0\n",
        "for word,i in tokenizer.word_index.items():\n",
        "    try:\n",
        "        embedding_matrix_ft[i] = ft.wv[word]\n",
        "    except:\n",
        "        pas+=1\n",
        "\n",
        "HIDDEN_UNITS = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U89qmWA7y7OI"
      },
      "source": [
        "Summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2rT8NDyy9Jm"
      },
      "source": [
        "# define dummy data and precproces them\n",
        "docs2 = short_summary\n",
        "\n",
        "# train fasttext from gensim api\n",
        "ft2 = FastText(size=10, window=2, min_count=1, seed=33)\n",
        "ft2.build_vocab(docs2)\n",
        "ft2.train(docs2, total_examples=ft2.corpus_count, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JDiEpozzDxS"
      },
      "source": [
        "tokenizer2 = tensorflow.keras.preprocessing.text.Tokenizer(lower=True)\n",
        "tokenizer2.fit_on_texts(docs2)\n",
        "\n",
        "sequence_docs2 = tokenizer2.texts_to_sequences(docs2)\n",
        "sequence_docs2 = tensorflow.keras.preprocessing.sequence.pad_sequences(sequence_docs2, maxlen=MAX_LEN)\n",
        "\n",
        "# extract fasttext learned embedding and put them in a numpy array\n",
        "embedding_matrix_ft2 = np.random.random((len(tokenizer2.word_index) + 1, ft2.vector_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTeMyo4x1ZDw",
        "outputId": "8d63ff8a-037b-47e6-e4c1-91e2fc323b40"
      },
      "source": [
        "len(tokenizer2.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "506"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGmpI3xRzmu8"
      },
      "source": [
        "pas2 = 0\n",
        "for word,i in tokenizer2.word_index.items():\n",
        "    try:\n",
        "        embedding_matrix_ft2[i] = ft2.wv[word]\n",
        "    except:\n",
        "        pas2 += 1\n",
        "\n",
        "HIDDEN_UNITS = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdz132E865wy"
      },
      "source": [
        "Corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQtXX9Of4tOu",
        "outputId": "a2e99334-3cc2-42cc-8094-67caaa6c6f30"
      },
      "source": [
        "corpus = short_text + short_summary\n",
        "len(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyhcc1Rp6-b5"
      },
      "source": [
        "# train fasttext from gensim api\n",
        "ft3 = FastText(size=10, window=3, min_count=1, seed=33)\n",
        "ft3.build_vocab(corpus)\n",
        "ft3.train(corpus, total_examples=ft2.corpus_count, epochs=10)\n",
        "\n",
        "tokenizer3 = tensorflow.keras.preprocessing.text.Tokenizer(lower=True)\n",
        "tokenizer3.fit_on_texts(corpus)\n",
        "\n",
        "# text\n",
        "sequence_text = tokenizer3.texts_to_sequences(corpus)\n",
        "sequence_text = tensorflow.keras.preprocessing.sequence.pad_sequences(sequence_text, maxlen=MAX_LEN)\n",
        "\n",
        "# summary\n",
        "sequence_summary = tokenizer3.texts_to_sequences(corpus)\n",
        "sequence_summary = tensorflow.keras.preprocessing.sequence.pad_sequences(sequence_summary, maxlen=MAX_LEN)\n",
        "\n",
        "# extract fasttext learned embedding and put them in a numpy array\n",
        "embedding_matrix_ft3 = np.random.random((len(tokenizer3.word_index) + 1, ft3.vector_size))\n",
        "\n",
        "pas3 = 0\n",
        "for word,i in tokenizer3.word_index.items():\n",
        "    try:\n",
        "        embedding_matrix_ft3[i] = ft3.wv[word]\n",
        "    except:\n",
        "        pas3 += 1\n",
        "\n",
        "HIDDEN_UNITS = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALwX9Up0znqJ"
      },
      "source": [
        "Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEjk015qxKbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa589aa-0ef6-4027-fe73-96c3b0a84139"
      },
      "source": [
        "# define a keras model and load the pretrained fasttext weights matrix\n",
        "encoder_inputs = Input(shape=(MAX_LEN,))\n",
        "\n",
        "# embedding layer\n",
        "enc_emb = Embedding(len(tokenizer3.word_index) + 1, ft.vector_size, \n",
        "                weights=[embedding_matrix_ft3], trainable=False)(encoder_inputs)\n",
        "\n",
        "# encoder lstm 1\n",
        "encoder_lstm1 = LSTM(HIDDEN_UNITS, return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "# encoder lstm 2\n",
        "encoder_lstm2 = LSTM(HIDDEN_UNITS, return_sequences=True,return_state=True,dropout=0.2,recurrent_dropout=0.2)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# encoder lstm 3\n",
        "encoder_lstm3 = LSTM(HIDDEN_UNITS, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(MAX_LEN,))\n",
        "\n",
        "# embedding layer\n",
        "dec_emb = Embedding(len(tokenizer3.word_index) + 1, ft2.vector_size, \n",
        "                weights=[embedding_matrix_ft3], trainable=False)(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True,dropout=0.3,recurrent_dropout=0.1)\n",
        "decoder_outputs1, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = Attention(name='attention_layer')\n",
        "attn_out = attn_layer([encoder_outputs, decoder_outputs1])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs1, attn_out])\n",
        "\n",
        "# dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(len(tokenizer3.word_index) + 1, activation='softmax'))\n",
        "decoder_outputs2 = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs2)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 120)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_14 (Embedding)        (None, 120, 10)      11980       input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_28 (LSTM)                  [(None, 120, 32), (N 5504        embedding_14[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_16 (InputLayer)           [(None, 120)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_29 (LSTM)                  [(None, 120, 32), (N 8320        lstm_28[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_15 (Embedding)        (None, 120, 10)      11980       input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_30 (LSTM)                  [(None, 120, 32), (N 8320        lstm_29[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_31 (LSTM)                  [(None, 120, 32), (N 5504        embedding_15[0][0]               \n",
            "                                                                 lstm_30[0][1]                    \n",
            "                                                                 lstm_30[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (Attention)     (None, 120, 32)      0           lstm_30[0][0]                    \n",
            "                                                                 lstm_31[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, 120, 64)      0           lstm_31[0][0]                    \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistrib (None, 120, 1198)    77870       concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 129,478\n",
            "Trainable params: 105,518\n",
            "Non-trainable params: 23,960\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvKVjouxXjiT"
      },
      "source": [
        "model.compile(optimizer=Adam(lr=0.0001), \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "RxOO036ZfumC",
        "outputId": "7abd2cb8-9dca-4115-f06d-8465220b74b3"
      },
      "source": [
        "\"\"\"es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2), \n",
        "      ModelCheckpoint('./MyModel_tf',monitor='val_loss', verbose=1,\n",
        "                      save_best_only=True, mode='min', save_weights_only = False)]\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2), \\n      ModelCheckpoint('./MyModel_tf',monitor='val_loss', verbose=1,\\n                      save_best_only=True, mode='min', save_weights_only = False)]\""
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doZE-Zuob1m9",
        "outputId": "a2b59add-b912-40bb-a364-3f7f169a88b6"
      },
      "source": [
        "model.fit([sequence_text, sequence_summary], sequence_summary,\n",
        "          batch_size=16,\n",
        "          epochs=50,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 12s 2s/step - loss: 7.0682 - accuracy: 0.0012 - val_loss: 7.0426 - val_accuracy: 0.0036\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 7.0662 - accuracy: 0.0012 - val_loss: 7.0388 - val_accuracy: 0.0036\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 7.0625 - accuracy: 0.0015 - val_loss: 7.0348 - val_accuracy: 0.0036\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 1s 590ms/step - loss: 7.0605 - accuracy: 0.0028 - val_loss: 7.0309 - val_accuracy: 0.0048\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 7.0576 - accuracy: 0.0025 - val_loss: 7.0269 - val_accuracy: 0.0048\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 1s 584ms/step - loss: 7.0551 - accuracy: 0.0025 - val_loss: 7.0229 - val_accuracy: 0.0048\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 1s 582ms/step - loss: 7.0526 - accuracy: 0.0031 - val_loss: 7.0188 - val_accuracy: 0.0048\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 1s 575ms/step - loss: 7.0500 - accuracy: 0.0025 - val_loss: 7.0147 - val_accuracy: 0.0048\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 1s 574ms/step - loss: 7.0471 - accuracy: 0.0031 - val_loss: 7.0106 - val_accuracy: 0.0060\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 1s 575ms/step - loss: 7.0448 - accuracy: 0.0028 - val_loss: 7.0064 - val_accuracy: 0.0060\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 1s 578ms/step - loss: 7.0411 - accuracy: 0.0028 - val_loss: 7.0021 - val_accuracy: 0.0060\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 7.0386 - accuracy: 0.0022 - val_loss: 6.9978 - val_accuracy: 0.0060\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 7.0351 - accuracy: 0.0022 - val_loss: 6.9934 - val_accuracy: 0.0060\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 1s 569ms/step - loss: 7.0326 - accuracy: 0.0028 - val_loss: 6.9888 - val_accuracy: 0.0060\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 1s 597ms/step - loss: 7.0296 - accuracy: 0.0037 - val_loss: 6.9843 - val_accuracy: 0.0060\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 7.0271 - accuracy: 0.0031 - val_loss: 6.9795 - val_accuracy: 0.0060\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 1s 590ms/step - loss: 7.0239 - accuracy: 0.0034 - val_loss: 6.9748 - val_accuracy: 0.0060\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 7.0203 - accuracy: 0.0028 - val_loss: 6.9698 - val_accuracy: 0.0060\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 7.0165 - accuracy: 0.0031 - val_loss: 6.9647 - val_accuracy: 0.0060\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 1s 590ms/step - loss: 7.0138 - accuracy: 0.0099 - val_loss: 6.9595 - val_accuracy: 0.0060\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 1s 579ms/step - loss: 7.0102 - accuracy: 0.0114 - val_loss: 6.9542 - val_accuracy: 0.0060\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 1s 584ms/step - loss: 7.0065 - accuracy: 0.0228 - val_loss: 6.9487 - val_accuracy: 0.0060\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 1s 578ms/step - loss: 7.0032 - accuracy: 0.0269 - val_loss: 6.9431 - val_accuracy: 0.0429\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 1s 586ms/step - loss: 7.0006 - accuracy: 0.0386 - val_loss: 6.9373 - val_accuracy: 0.0488\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 1s 581ms/step - loss: 6.9961 - accuracy: 0.0840 - val_loss: 6.9314 - val_accuracy: 0.0571\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 1s 589ms/step - loss: 6.9907 - accuracy: 0.1136 - val_loss: 6.9252 - val_accuracy: 0.2357\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 1s 586ms/step - loss: 6.9867 - accuracy: 0.1688 - val_loss: 6.9188 - val_accuracy: 0.3964\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 6.9834 - accuracy: 0.2059 - val_loss: 6.9122 - val_accuracy: 0.5905\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 1s 583ms/step - loss: 6.9773 - accuracy: 0.2747 - val_loss: 6.9053 - val_accuracy: 0.5952\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 6.9742 - accuracy: 0.2793 - val_loss: 6.8981 - val_accuracy: 0.5964\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 6.9705 - accuracy: 0.2932 - val_loss: 6.8907 - val_accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 1s 561ms/step - loss: 6.9644 - accuracy: 0.3022 - val_loss: 6.8831 - val_accuracy: 0.6000\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 6.9601 - accuracy: 0.3046 - val_loss: 6.8752 - val_accuracy: 0.6000\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 1s 578ms/step - loss: 6.9546 - accuracy: 0.3056 - val_loss: 6.8671 - val_accuracy: 0.6000\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 1s 578ms/step - loss: 6.9486 - accuracy: 0.3059 - val_loss: 6.8586 - val_accuracy: 0.6000\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 1s 580ms/step - loss: 6.9430 - accuracy: 0.3056 - val_loss: 6.8498 - val_accuracy: 0.6000\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 6.9367 - accuracy: 0.3059 - val_loss: 6.8407 - val_accuracy: 0.6000\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 1s 587ms/step - loss: 6.9309 - accuracy: 0.3062 - val_loss: 6.8312 - val_accuracy: 0.6000\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 6.9243 - accuracy: 0.3062 - val_loss: 6.8215 - val_accuracy: 0.6000\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 1s 585ms/step - loss: 6.9176 - accuracy: 0.3062 - val_loss: 6.8114 - val_accuracy: 0.6000\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 1s 597ms/step - loss: 6.9109 - accuracy: 0.3062 - val_loss: 6.8008 - val_accuracy: 0.6000\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 1s 588ms/step - loss: 6.9046 - accuracy: 0.3062 - val_loss: 6.7899 - val_accuracy: 0.6000\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 6.8962 - accuracy: 0.3062 - val_loss: 6.7786 - val_accuracy: 0.6000\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 1s 583ms/step - loss: 6.8879 - accuracy: 0.3062 - val_loss: 6.7671 - val_accuracy: 0.6000\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 6.8809 - accuracy: 0.3062 - val_loss: 6.7551 - val_accuracy: 0.6000\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 1s 584ms/step - loss: 6.8727 - accuracy: 0.3062 - val_loss: 6.7428 - val_accuracy: 0.6000\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 1s 580ms/step - loss: 6.8646 - accuracy: 0.3062 - val_loss: 6.7301 - val_accuracy: 0.6000\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 6.8542 - accuracy: 0.3062 - val_loss: 6.7171 - val_accuracy: 0.6000\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 1s 585ms/step - loss: 6.8483 - accuracy: 0.3062 - val_loss: 6.7036 - val_accuracy: 0.6000\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 6.8383 - accuracy: 0.3062 - val_loss: 6.6899 - val_accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe495ada890>"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta4FzFGHccD6"
      },
      "source": [
        "# Save model\n",
        "model.save('myAttentionSeq2seq_125.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwXqc3dJlNYr",
        "outputId": "ddeee446-214d-4252-cbf2-ba80f098ebe9"
      },
      "source": [
        "pred = model.predict([sequence_text[0], sequence_summary[0]])\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 120) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.float32, name='input_15'), name='input_15', description=\"created by layer 'input_15'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 120) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.float32, name='input_16'), name='input_16', description=\"created by layer 'input_16'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.00090695, 0.00087093, 0.00086491, ..., 0.00079503,\n",
              "         0.00079808, 0.00082482]],\n",
              "\n",
              "       [[0.00090695, 0.00087093, 0.00086491, ..., 0.00079503,\n",
              "         0.00079808, 0.00082482]],\n",
              "\n",
              "       [[0.00090695, 0.00087093, 0.00086491, ..., 0.00079503,\n",
              "         0.00079808, 0.00082482]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.00093567, 0.00087686, 0.00088251, ..., 0.00076209,\n",
              "         0.00077493, 0.00082434]],\n",
              "\n",
              "       [[0.00094849, 0.00088099, 0.00087884, ..., 0.00076659,\n",
              "         0.00078043, 0.00083117]],\n",
              "\n",
              "       [[0.00092717, 0.00087626, 0.00087345, ..., 0.00077441,\n",
              "         0.00078738, 0.00083236]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-MYDIAhQ-v9"
      },
      "source": [
        "reverse_word_index = dict(\n",
        "    (i, word) for word, i in tokenizer3.word_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3F085CWHnWA"
      },
      "source": [
        "def prediction_text(some_text):\n",
        "  pred_text = tokenizer3.texts_to_sequences(text_cleaner(some_text))\n",
        "  pred_text = tensorflow.keras.preprocessing.sequence.pad_sequences(pred_text, maxlen=MAX_LEN)\n",
        "\n",
        "  pred_seq = model.predict([pred_text, pred_text])\n",
        "\n",
        "  t = \"\"\n",
        "  for p in pred_seq:\n",
        "    t += reverse_word_index[np.argmax(p[0]) + 1] + \" \"\n",
        "\n",
        "  return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "AxDbIP1TTGWq",
        "outputId": "e9c1e9cc-c622-4f20-94b0-9f654042850b"
      },
      "source": [
        "short_text[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'summarythis case report describes year old woman presented bilateral femoral stress fractures osteoporosis years excessive levothyroxine treatment bone health restored rapidly long lasting reduction levothyroxine dosage bone active treatment warranted introductionhyperthyroidism known risk factor osteoporosis fractures recent studies patients serum thyrotropin suppressive therapy however indicated adverse effects bone long term follow case report describes long term follow data clinically euthyreoid patient developed symptomatic osteoporosis due excessive levothyroxine treatment correction levothyroxine dosage bone mineral density previously elevated serum osteocalcin levels normalized rapidly remained free fractures years follow menopause conclusionexcessive tsh suppression contributed secondary osteoporosis patient bmd normalized dose reduction levothyroxine fractures occurred years follow patients develop severe osteoporosis substituted levothyroxine decent follow patients levothyroxine supplementation mandatory'"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzPTw0a1RvKI"
      },
      "source": [
        "pred = model.predict([sequence_text[2], sequence_summary[2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "Cukkfj9Ra6ar",
        "outputId": "07bc7d82-c09f-4f33-ad71-be4daa45059d"
      },
      "source": [
        "t = \"\"\n",
        "for p in pred:\n",
        "  t += reverse_word_index[np.argmax(p[0]) + 1] + \" \"\n",
        "\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months months osteoporosis second osteoporosis second patients months patients months months months second patients months patients months patients patients second osteoporosis months months patients patients osteoporosis osteoporosis patients osteoporosis second months patients patients second osteoporosis second patients osteoporosis second osteoporosis patients osteoporosis months months osteoporosis patients months patients months second osteoporosis months patients patients months osteoporosis patients second months months patients second months osteoporosis patients months months second months patients osteoporosis second patients osteoporosis patients second months '"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    }
  ]
}